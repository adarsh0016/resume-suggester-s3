spring.application.name=resumedS3


# S3 config
aws.s3.region=${RESUME_SUGGESTOR_S3_REGION}
aws.s3.bucket-name=${RESUME_SUGGESTOR_S3_BUCKET_NAME}
aws.s3.endpoint=${RESUME_SUGGESTOR_S3_ENDPOINT}

server.port=8081


# kafka config
spring.kafka.bootstrap-servers=${RESUMED_KAFKA_BROKER_URL}
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${RESUMED_KAFKA_USERNAME}" password="${RESUMED_KAFKA_PASSWORD}";
spring.kafka.consumer.group-id=resumed-be
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
spring.kafka.consumer.properties.spring.json.use.type.headers=false
spring.kafka.consumer.properties.spring.json.value.default.type=com.adarsh.resumedS3.DTO.uploadRequest